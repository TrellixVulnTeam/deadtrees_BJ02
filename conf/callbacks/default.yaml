model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/dice" #"val/total_loss"  # name of the logged metric which determines when model is improving
    save_top_k: 1              # save k best models (determined by above metric)
    save_last: True            # additionaly always save model from last epoch
    mode: "max" #"min"                # can be "max" or "min"
    verbose: False
    dirpath: 'checkpoints/'
    filename: '{epoch:02d}'


early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val/dice" #"val/total_loss"  # name of the logged metric which determines when model is improving
    patience: 200              # how many epochs of not improving until training stops
    mode: "max" #"min"                # can be "max" or "min"
    min_delta: 0.00001               # minimum change in the monitored metric needed to qualify as an improvement


learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"
